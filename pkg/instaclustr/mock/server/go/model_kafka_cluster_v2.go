/*
 * Instaclustr Cluster Management API
 *
 * Instaclustr Cluster Management API
 *
 * API version: 2.0.0
 * Generated by: OpenAPI Generator (https://openapi-generator.tech)
 */

package openapi

// KafkaClusterV2 - Definition of a managed Kafka cluster that can be provisioned in Instaclustr.
type KafkaClusterV2 struct {

	// Enables Client ⇄ Broker Authentication with mTLS.
	ClientBrokerAuthWithMtls bool `json:"clientBrokerAuthWithMtls,omitempty"`

	// Creates a PCI compliant cluster, see [PCI Compliance](https://www.instaclustr.com/support/documentation/useful-information/pci-compliance/).
	PciComplianceMode bool `json:"pciComplianceMode"`

	// Adds the specified version of Kafka Schema Registry to this Kafka cluster.
	SchemaRegistry []KafkaSchemaRegistryDetailsV2 `json:"schemaRegistry,omitempty"`

	// Default Replication factor to use for new topic. Also represents the number of racks to use when allocating nodes.
	DefaultReplicationFactor int32 `json:"defaultReplicationFactor"`

	// Default number of partitions to use when created new topics.
	DefaultNumberOfPartitions int32 `json:"defaultNumberOfPartitions"`

	// Enables Client ⇄ Broker Authentication without Encryption.
	ClientAuthBrokerWithoutEncryption bool `json:"clientAuthBrokerWithoutEncryption,omitempty"`

	//
	TwoFactorDelete []TwoFactorDeleteSettingsV2 `json:"twoFactorDelete,omitempty"`

	// Adds the specified version of Kafka Karapace REST Proxy to this Kafka cluster.
	KarapaceRestProxy []KafkaKarapaceRestProxyDetailsV2 `json:"karapaceRestProxy,omitempty"`

	// Allows topics to be deleted via the kafka-topics tool
	AllowDeleteTopics bool `json:"allowDeleteTopics"`

	// Allows topics to be auto created by brokers when messages are published to a non-existent topic
	AutoCreateTopics bool `json:"autoCreateTopics"`

	// Adds the specified version of Kafka Karapace Schema Registry to this Kafka cluster.
	KarapaceSchemaRegistry []KafkaKarapaceSchemaRegistryDetailsV2 `json:"karapaceSchemaRegistry,omitempty"`

	// Adds the specified version of Kafka REST Proxy to this Kafka cluster.
	RestProxy []KafkaRestProxyDetailsV2 `json:"restProxy,omitempty"`

	// Enables Client ⇄ Cluster Encryption.
	ClientToClusterEncryption bool `json:"clientToClusterEncryption"`

	// List of data centre settings.
	DataCentres []KafkaDataCentreV2 `json:"dataCentres"`

	CurrentClusterOperationStatus CurrentClusterOperationStatusV2 `json:"currentClusterOperationStatus,omitempty"`

	// Provision additional dedicated nodes for Apache Zookeeper to run on. Zookeeper nodes will be co-located with Kafka if this is not provided
	DedicatedZookeeper []KafkaDedicatedZookeeperSettingsV2 `json:"dedicatedZookeeper,omitempty"`

	// Creates the cluster with private network only, see [Private Network Clusters](https://www.instaclustr.com/support/documentation/useful-information/private-network-clusters/).
	PrivateNetworkCluster bool `json:"privateNetworkCluster"`

	// Version of Kafka to run on the cluster. Available versions: <ul> <li>`3.0.2`</li> <li>`3.1.2`</li> <li>`2.8.2`</li> <li>`2.7.1`</li> </ul>
	KafkaVersion string `json:"kafkaVersion"`

	// Name of the cluster.
	Name string `json:"name"`

	// Enables Client ⇄ Broker Authentication with Encryption.
	ClientAuthBrokerWithEncryption bool `json:"clientAuthBrokerWithEncryption,omitempty"`

	// ID of the cluster.
	Id string `json:"id,omitempty"`

	SlaTier SlaTierV2 `json:"slaTier"`

	// Status of the cluster.
	Status string `json:"status,omitempty"`
}

// AssertKafkaClusterV2Required checks if the required fields are not zero-ed
func AssertKafkaClusterV2Required(obj KafkaClusterV2) error {
	elements := map[string]interface{}{
		"pciComplianceMode":         obj.PciComplianceMode,
		"defaultReplicationFactor":  obj.DefaultReplicationFactor,
		"defaultNumberOfPartitions": obj.DefaultNumberOfPartitions,
		"allowDeleteTopics":         obj.AllowDeleteTopics,
		"autoCreateTopics":          obj.AutoCreateTopics,
		"clientToClusterEncryption": obj.ClientToClusterEncryption,
		"dataCentres":               obj.DataCentres,
		"privateNetworkCluster":     obj.PrivateNetworkCluster,
		"kafkaVersion":              obj.KafkaVersion,
		"name":                      obj.Name,
		"slaTier":                   obj.SlaTier,
	}
	for name, el := range elements {
		if isZero := IsZeroValue(el); isZero {
			return &RequiredError{Field: name}
		}
	}

	for _, el := range obj.SchemaRegistry {
		if err := AssertKafkaSchemaRegistryDetailsV2Required(el); err != nil {
			return err
		}
	}
	for _, el := range obj.TwoFactorDelete {
		if err := AssertTwoFactorDeleteSettingsV2Required(el); err != nil {
			return err
		}
	}
	for _, el := range obj.KarapaceRestProxy {
		if err := AssertKafkaKarapaceRestProxyDetailsV2Required(el); err != nil {
			return err
		}
	}
	for _, el := range obj.KarapaceSchemaRegistry {
		if err := AssertKafkaKarapaceSchemaRegistryDetailsV2Required(el); err != nil {
			return err
		}
	}
	for _, el := range obj.RestProxy {
		if err := AssertKafkaRestProxyDetailsV2Required(el); err != nil {
			return err
		}
	}
	for _, el := range obj.DataCentres {
		if err := AssertKafkaDataCentreV2Required(el); err != nil {
			return err
		}
	}
	for _, el := range obj.DedicatedZookeeper {
		if err := AssertKafkaDedicatedZookeeperSettingsV2Required(el); err != nil {
			return err
		}
	}
	return nil
}

// AssertRecurseKafkaClusterV2Required recursively checks if required fields are not zero-ed in a nested slice.
// Accepts only nested slice of KafkaClusterV2 (e.g. [][]KafkaClusterV2), otherwise ErrTypeAssertionError is thrown.
func AssertRecurseKafkaClusterV2Required(objSlice interface{}) error {
	return AssertRecurseInterfaceRequired(objSlice, func(obj interface{}) error {
		aKafkaClusterV2, ok := obj.(KafkaClusterV2)
		if !ok {
			return ErrTypeAssertionError
		}
		return AssertKafkaClusterV2Required(aKafkaClusterV2)
	})
}
